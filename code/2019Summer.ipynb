{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2019Summer.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":["m3of9qXlEd6o","-002O-kB9LUB","pson6Itl9PI8","Sw9uddryFl2-"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_f3N3U_t9aVY","colab_type":"text"},"source":["## read from arduino to txt"]},{"cell_type":"code","metadata":{"id":"GhOY8TMMD_55","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2r2OeTctD_5_","colab_type":"code","colab":{}},"source":["fig, ax = plt.subplots()\n","line, = ax.plot(np.random.rand(10))\n","# ax.set_ylim(-5000, 5000)\n","# xdata, ydata = [0]*100, [0]*100\n","myPort = serial.Serial(\"COM4\",500000)\n","# raw.open()\n","\n","#bufferSize is the length of the input buffer\n","#batchSize is the length of list store in one line in the file\n","bufferSize = 2048\n","batchSize = 64\n","idx = 0\n","\n","with open('cjc.txt', 'w') as file:\n","    pass\n","f = open('cjc.txt', 'a')\n","def read_serial():\n","    carve = 0\n","    highByte = 0\n","    lowByte = 0\n","    buffer = np.zeros(bufferSize)\n","    while (myPort.in_waiting < bufferSize):\n","        pass\n","    for i in range(bufferSize):\n","        carve = ord(myPort.read())\n","        while (carve != ord(b'\\xff')):\n","            carve = ord(myPort.read())\n","        while (myPort.in_waiting < 2):\n","            pass\n","        highByte = ord(myPort.read())\n","        lowByte = ord(myPort.read())\n","        buffer[i] = highByte << 8 | lowByte\n","    # plt.scatter(pltx, plty, s=0.1)\n","    # plt.show()\n","    # plt.pause(0.0001)\n","    \n","    print(buffer)\n","    np.savetxt(f,buffer,delimiter=',')\n","    return buffer\n","\n","\n","def update(data):\n","    line.set_ydata(data)\n","    return line,\n","\n","def run(data):\n","    t,y = data\n","    line.set_data(t, y)\n","    return line,\n","\n","def data_gen():\n","    pltx = np.array([])\n","    plty = np.array([])\n","    global idx\n","    while True:\n","        try:\n","            dat = read_serial()\n","            \n","        except:\n","            dat = np.zeros(bufferSize)\n","\n","        plt.axis([idx-20480, idx+bufferSize, -100, 700])\n","        for i in range(bufferSize):\n","            pltx=np.append(pltx,idx)\n","            idx += 1\n","        # print(dat)\n","        plty = np.concatenate((plty,dat))\n","        pltx = pltx[-20480:]\n","        plty = plty[-20480:]\n","        yield pltx, plty\n","\n","ani = animation.FuncAnimation(fig, run, data_gen, interval=0, blit=True)\n","plt.show()\n","f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHou1c3c2_Lx","colab_type":"code","colab":{}},"source":["myPort.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3of9qXlEd6o","colab_type":"text"},"source":["## Read data from txt and process"]},{"cell_type":"code","metadata":{"id":"BU1L1Mr73JsX","colab_type":"code","colab":{}},"source":["print(np.zeros(bufferSize))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejQ75ISeEiV5","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","\n","batchSize = 2048\n","\n","with open(\"file1.txt\",'r') as file:\n","    y = np.loadtxt(file,delimiter=',')\n","print(y.shape)\n","y = np.reshape(y,(-1,batchSize))\n","y = np.reshape(y,(1,-1))\n","print(y.shape)\n","segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","y = segment.transform(y)[0]\n","print(y.shape)\n","maxy = maximum(y)\n","miny = minimum(y)\n","print(maxy.shape)\n","print(miny.shape)\n","# y=np.transpose(y)\n","# scaler = MinMaxScaler()\n","# scaler.fit(y)\n","# y=scaler.transform(y)\n","# y=np.transpose(y)\n","# y = y-np.mean(y)\n","print(y)\n","loi = y[0:10]\n","loi = np.reshape(loi,(1,-1))\n","loi = loi[0]\n","# loi[loi>1000] = np.mean(y)\n","print(loi.size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMchKsecLX7S","colab_type":"code","colab":{}},"source":["#list_of_interest\n","from scipy.signal import *\n","peaks = find_peaks_cwt(loi,np.arange(1,100))\n","max_peak_idx = np.argmax(loi[peaks])\n","peaks_needed = 4\n","proper_peaks = [max_peak_idx-i for i in range(-3,peaks_needed) ]\n","proper_peaks = peaks[proper_peaks]\n","# print(proper_peaks)\n","\n","plt.plot(loi)\n","plt.plot(peaks,loi[peaks],\"x\")\n","plt.plot(proper_peaks,loi[proper_peaks],\"o\")\n","# plt.axis([6000, 10000, -100, 150])\n","plt.show()\n","# print(peaks.size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_cc2R4u9Ert","colab_type":"code","colab":{}},"source":["from scipy import signal\n","\n","plt.plot(loi)\n","plt.show()\n","plt.figure()\n","plt.plot(signal.detrend(loi))\n","plt.figure()\n","plt.plot(np.abs(np.fft.rfft(loi[13000:15500])))\n","numpy.fft.fftfreq(len(loi[13000:15500]))\n","plt.axis([0,100,0,100000])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7LNrYyH9FCX","colab_type":"text"},"source":["## different objects"]},{"cell_type":"code","metadata":{"id":"T6-ifFFeFU1h","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","import math\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy.signal import find_peaks\n","    \n","batchSize = 2048\n","file_names = [\"1pad_back\",\"2pad_front\",\"3storage_box\",\"4blue_lid\",\"5coffee_mug\",\"6mujie_hand\",\"7paper_box\",\"8surface_cover\",\"9moniter\",\"10black_book\",\"11metal_grid\"\n","             \"12lamp_top\",\"13phone\"]\n","metal_names = [\"1pad_back\",\"2pad_front\",\"5coffee_mug\",\"11metal_grid\",\"12lamp_top\",\"13phone\",\"14can\",\"15shovel\"]\n","\n","\n","for i in range(len(metal_names)):\n","    cur_names = metal_names[i] + \".txt\"\n","    with open(cur_names,'r') as file:\n","        y = np.loadtxt(file,delimiter=',')\n","    print(y.shape)\n","    y = np.reshape(y,(-1,batchSize))\n","    y = np.reshape(y,(1,-1))\n","#     print(y.shape)\n","    segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","    y = segment.transform(y)[0]\n","#     print(y.shape)\n","    maxy = maximum(y)\n","    miny = minimum(y)\n","    \n","    if(cur_names==\"1pad_back.txt\"): \n","        loi = 800 - y[-23:-5].reshape(1,-1)[0]\n","    else:\n","        loi = 800 - y.reshape(1,-1)[0][200:]\n","    np.delete(loi, loi>1000)\n","    print(loi)\n","    # automatic pick 11 peaks\n","    loi_mean = loi - np.mean(loi)\n","    peaks,_ = find_peaks(loi_mean,distance=100, height = 50, width = 10)\n","    max_peak_idx = np.argmax(loi[peaks])\n","#     print(max_peak_idx)\n","    print()\n","    peaks_needed = 11\n","    proper_peaks = [max_peak_idx-i for i in range(-int(peaks_needed/2),math.ceil(peaks_needed/2))]\n","    proper_peaks = peaks[proper_peaks]\n","    \n","    \n","#     plt.plot(proper_peaks,loi[proper_peaks],\"o\")\n","    plt.figure(figsize=(10,3))\n","    plt.plot(loi)\n","    plt.plot(proper_peaks,loi[proper_peaks],\"x\")\n","#     plt.plot(peaks,loi[peaks],\"x\")\n","\n","    plt.plot(peaks[max_peak_idx],loi[peaks[max_peak_idx]],\"o\")\n","    plt.axis([peaks[0],peaks[-1],150,800])\n","#     plt.plot(range(len(loi)),loi,markersize=1)\n","    for i in proper_peaks:\n","        plt.text(i,loi[i],str(loi[i]))\n","    \n","    plt.show()\n","    # np.savetxt\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-002O-kB9LUB","colab_type":"text"},"source":["## height cross validation"]},{"cell_type":"code","metadata":{"id":"mUGq2UNtStsR","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","import math\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy import signal\n","import heapq\n","\n","\n","def find_peaks(L, mean_thres = 0, height_thres = 0, width = 200, mode = 1):\n","    res = []\n","    upper=[]\n","    lower=[]\n","    register = 0\n","    mean = np.mean(L[-200:])\n","    \n","    if(mean_thres == 0):\n","        mean_thres = np.ptp(L)/20\n","    if(height_thres == 0):\n","        height_thres = mean_thres\n","    plt.figure(figsize=(8,2))\n","#     plt.hlines(mean+mean_thres,0,len(L))    \n","#     plt.hlines(mean,0,len(L))\n","\n","    # status flag\n","    # 0 -- starting\n","    # 1 -- \n","    # 2 -- not determined\n","    # 3 -- not determined\n","    # 4 -- not determined\n","\n","    status = 0 \n","    jump_flag = 0\n","    i = 0\n","#     for i in range(len(L)-1):\n","    while(True):\n","        i+=1\n","        if(i+1 >= len(L)):\n","            break\n","        \n","        if(L[i] > max(mean_thres,height_thres) + mean or L[i] < - max(mean_thres,height_thres) + mean):\n","            if(L[i] > max(mean_thres,height_thres) + mean):\n","                status=1\n","            else:\n","                status=3\n","            if(status==1):\n","                #开始下降\n","                if(L[i]>L[i+1]):\n","                    #未来width个点没有比这个更高的 || 低下了mean下thres\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] >= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif( L[i+j] < - mean_thres + mean):\n","                            res.append(i)\n","                            upper.append(i)\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","\n","            elif(status==3):\n","                if(L[i]<=L[i+1]):\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] <= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif(L[i+j]>mean_thres+mean):\n","                            res.append(i)\n","                            lower.append(i)\n","                            i=i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","    \n","    \n","    lower = np.array(lower)\n","    upper = np.array(upper)\n","    res = np.array(res)\n","\n","    # ----------------------- filter the middle --------------------------------\n","    #mode = 0 filter using upper\n","    #       1 filter using lower\n","    #       2 no filtering\n","    if (mode == 1):\n","        filter_list = np.argsort(L[lower])[:2]\n","        filter_list = lower[filter_list]\n","        filter_list = np.sort(filter_list)\n","        lower = lower[ (filter_list[0] >= lower) | (lower >= filter_list[1])]\n","        upper = upper[ (filter_list[0] >= upper) | (upper >= filter_list[1])]\n","        res = res[ (filter_list[0] >= res) | (res >= filter_list[1])]\n","    elif (mode == 2):\n","        pass\n","    else:\n","        filter_list = np.argsort(L[upper])[-2:]\n","        filter_list = upper[filter_list]\n","        lower = lower[ (filter_list[0] >= lower) | (lower >= filter_list[1])]\n","        upper = upper[ (filter_list[0] >= upper) | (upper >= filter_list[1])]\n","        res = res[ (filter_list[0] >= res) | (res >= filter_list[1])]\n","    \n","    return (res,upper,lower)\n","   \n","batchSize = 2048\n","file_names = [\"1pad_back\",\"2pad_front\",\"3storage_box\",\"4blue_lid\",\"5coffee_mug\",\"6mujie_hand\",\"7paper_box\",\"8surface_cover\",\"9moniter\",\"10black_book\",\"11metal_grid\"\n","             \"12lamp_top\",\"13phone\"]\n","metal_names = [\"1pad_back\",\"2pad_front\",\"3coffee_mug\",\"4metal_grid\",\"5lamp_top\",\"6phone\",\"7shovel\",\"8can\"]\n","mono_names = [\"CoffeeCan\",\"EmptyCan\",\"PadBack\"]\n","\n","\n","for i in range(len(mono_names)):\n","    for k in range(1,3):\n","        for j in range(1,3):\n","            cur_names = \"DataForDifferentSpeedInHeight_3/3_\" + mono_names[i] + \"_speed\" + str(k) + \"_trial\" + str(j) + \".txt\"\n","            try:\n","                with open(cur_names,'r') as file:\n","                    y = np.loadtxt(file,delimiter=',')\n","            except:\n","                continue\n","            y = np.reshape(y,(-1,batchSize))\n","            y = np.reshape(y,(1,-1))\n","            segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","            y = segment.transform(y)[0]\n","\n","            loi = y.reshape(1,-1)[0][200:]\n","            np.delete(loi, loi>1000)\n","            plt.figure(figsize=(10,3))\n","            # -------------------------------------automatic pick peaks--------------------------------\n","            peaks,upper,lower = find_peaks(loi,height_thres=3,mean_thres=3,width = 20,mode=1)\n","\n","    #         plt.plot(loi)\n","    #         plt.plot(upper,loi[upper],\"x\")\n","    #         plt.plot(lower,loi[lower],\"o\")\n","            plt.plot(np.arange(0,len(upper)),loi[upper])\n","            plt.plot(np.arange(0,len(lower)),loi[lower])\n","            plt.title(cur_names)\n","            plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UT02fvE9PKg","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"pson6Itl9PI8","colab_type":"text"},"source":["## Miscellaneous"]},{"cell_type":"markdown","metadata":{"id":"M2nk0XIx9PCJ","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"PP-EIbI5H1Vw","colab_type":"code","colab":{}},"source":["\n","fig, ax = plt.subplots()\n","idx=0\n","def update(data):\n","    line.set_ydata(data)\n","    return line,\n","\n","def run(data):\n","    t,y = data\n","    line.set_data(t, y)\n","    return line,\n","\n","def data_gen():\n","    pltx = np.array([])\n","    plty = np.array([])\n","    global idx\n","    for i in y:\n","        try:\n","            dat = i\n","            \n","        except:\n","            dat = np.zeros(batchSize)\n","\n","        plt.axis([idx-20480, idx+batchSize, 0, 1])\n","        for i in range(batchSize):\n","            pltx=np.append(pltx,idx)\n","            idx += 1\n","        # print(dat)\n","        plty = np.concatenate((plty,dat))\n","        pltx = pltx[-20480:]\n","        plty = plty[-20480:]\n","        yield pltx, plty\n","\n","ani = animation.FuncAnimation(fig, run, data_gen, interval=0, blit=True)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDEfqzQeKOt6","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","import math\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy.signal import find_peaks\n","    \n","batchSize = 2048\n","\n","metal_names = [\"height/4metal_grid_4\"]\n","i=0\n","cur_names = metal_names[i] + \".txt\"\n","with open(cur_names,'r') as file:\n","    y = np.loadtxt(file,delimiter=',')\n","print(y.shape)\n","y = np.reshape(y,(-1,batchSize))\n","y = np.reshape(y,(1,-1))\n","#     print(y.shape)\n","segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","y = segment.transform(y)[0]\n","#     print(y.shape)\n","maxy = maximum(y)\n","miny = minimum(y)\n","#     print(maxy.shape)\n","#     print(miny.shape)\n","# y=np.transpose(y)\n","# scaler = MinMaxScaler()\n","# scaler.fit(y)\n","# y=scaler.transform(y)\n","# y=np.transpose(y)\n","# y = y-np.mean(y)\n","\n","#find the range\n","\n","if(cur_names==\"1pad_back.txt\"): \n","    loi = 800 - y[-23:-5].reshape(1,-1)[0]\n","else:\n","    loi = 800 - y.reshape(1,-1)[0][200:]\n","np.delete(loi, loi>1000)\n","print(loi)\n","# automatic pick 11 peaks\n","loi_mean = loi - np.mean(loi)\n","peaks,_ = find_peaks(loi_mean,distance=100, height = 20, width = 10)\n","max_peak_idx = np.argmax(loi[peaks])\n","#     print(max_peak_idx)\n","print()\n","peaks_needed = 11\n","proper_peaks = [max_peak_idx-i for i in range(-int(peaks_needed/2),math.ceil(peaks_needed/2))]\n","proper_peaks = peaks[proper_peaks]\n","\n","\n","#     plt.plot(proper_peaks,loi[proper_peaks],\"o\")\n","\n","plt.subplot(4,3,i+1)\n","plt.figure(figsize=(10,3))\n","plt.plot(loi)\n","plt.plot(proper_peaks,loi[proper_peaks],\"x\")\n","#     plt.plot(peaks,loi[peaks],\"x\")\n","\n","plt.plot(peaks[max_peak_idx],loi[peaks[max_peak_idx]],\"o\")\n","plt.axis([peaks[0],peaks[-1],150,800])\n","#     plt.plot(range(len(loi)),loi,markersize=1)\n","for i in proper_peaks:\n","    plt.text(i,loi[i],str(loi[i]))\n","\n","plt.show()\n","# np.savetxt\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLkdzeGVKZ-2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy import fftpack\n","\n","batchSize = 2048\n","\n","with open(\"file1.txt\",'r') as file:\n","    y = np.loadtxt(file,delimiter=',')\n","print(y.shape)\n","y = np.reshape(y,(-1,batchSize))\n","y = np.reshape(y,(1,-1))\n","print(y.shape)\n","segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","y = segment.transform(y)[0]\n","print(y.shape)\n","maxy = maximum(y)\n","miny = minimum(y)\n","print(maxy.shape)\n","print(miny.shape)\n","# y=np.transpose(y)\n","# scaler = MinMaxScaler()\n","# scaler.fit(y)\n","# y=scaler.transform(y)\n","# y=np.transpose(y)\n","y = y-np.mean(y)\n","\n","y = y.reshape(1,-1)[0]\n","\n","print(y)\n","np.delete(y, y>1000)\n","hx = fftpack.hilbert(y)\n","hy = np.sqrt(y**2+hx**2)\n","plt.figure(figsize=(10,3))\n","plt.plot(hy)\n","plt.plot(y)\n","plt.axis([2000,50000,-100,600])\n","plt.show()\n","y = -y\n","plt.figure(figsize=(10,3))\n","plt.plot(hy)\n","plt.plot(y)\n","plt.axis([2000,50000,-100,600])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ldOa9M7_TR7S","colab_type":"code","colab":{}},"source":["from scipy import signal\n","xs = np.arange(0, np.pi, 0.05)\n","data = np.sin(xs)\n","peakind = signal.find_peaks_cwt(data, np.arange(1,10))\n","peakind, xs[peakind], data[peakind]\n","plt.plot(data)\n","plt.plot(peakind,data[peakind],\"x\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h7b5JxUlcEnr","colab_type":"text"},"source":["## peak algorithm"]},{"cell_type":"code","metadata":{"id":"Pg_Hut9Jf5R2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy import signal\n","import heapq\n","\n","def find_peaks(L, mean_thres = 0, height_thres = 0, width = 200, mode = 0):\n","    res = []\n","    upper=[]\n","    lower=[]\n","    register = 0\n","#     mean = L[0] - signal.detrend(L)[0]-2\n","    mean = 0\n","    \n","    if(mean_thres == 0):\n","        mean_thres = np.ptp(L)/20\n","    if(height_thres == 0):\n","        height_thres = mean_thres\n","    plt.figure(figsize=(20,8))\n","#     plt.hlines(mean+mean_thres,0,len(L))    \n","#     plt.hlines(mean,0,len(L))\n","\n","    # status flag\n","    # 0 -- starting\n","    # 1 -- \n","    # 2 -- not determined\n","    # 3 -- not determined\n","    # 4 -- not determined\n","\n","    status = 0 \n","    jump_flag = 0\n","    i = 0\n","#     for i in range(len(L)-1):\n","    while(True):\n","        i+=1\n","        if(i+1 >= len(L)):\n","            break\n","        \n","        if(L[i] > max(mean_thres,height_thres) + mean or L[i] < - max(mean_thres,height_thres) + mean):\n","            if(L[i] > max(mean_thres,height_thres) + mean):\n","                status=1\n","            else:\n","                status=3\n","            if(status==1):\n","                #开始下降\n","                if(L[i]>L[i+1]):\n","                    #未来width个点没有比这个更高的 || 低下了mean下thres\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] >= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif( L[i+j] < - mean_thres + mean):\n","                            res.append(i)\n","                            upper.append(i)\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","\n","            elif(status==3):\n","                if(L[i]<=L[i+1]):\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] <= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif(L[i+j]>mean_thres+mean):\n","                            res.append(i)\n","                            lower.append(i)\n","                            i=i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","    \n","    \n","    lower = np.array(lower)\n","    upper = np.array(upper)\n","    res = np.array(res)\n","\n","    # ----------------------- filter the middle --------------------------------\n","    #mode = 0 filter using upper\n","    #       1 filter using lower\n","    #       2 no filtering\n","    if (mode == 1):\n","        print(\"cjc\")\n","        filter_list = np.argsort(L[lower])[:2]\n","        filter_list = lower[filter_list]\n","        filter_list = np.sort(filter_list)\n","        print(filter_list)\n","        lower = lower[ (filter_list[0] >= lower) | (lower >= filter_list[1])]\n","        upper = upper[ (filter_list[0] >= upper) | (upper >= filter_list[1])]\n","        res = res[ (filter_list[0] >= res) | (res >= filter_list[1])]\n","    elif (mode == 2):\n","        pass\n","    else:\n","        filter_list = np.argsort(L[upper])[-2:]\n","        filter_list = upper[filter_list]\n","        lower = lower[ (filter_list[0] >= lower) | (lower >= filter_list[1])]\n","        upper = upper[ (filter_list[0] >= upper) | (upper >= filter_list[1])]\n","        res = res[ (filter_list[0] >= res) | (res >= filter_list[1])]\n","    \n","    return (res,upper,lower)\n","                        \n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","# import matplotlib.animation as animation\n","# import serial\n","# from seglearn.transform import SegmentX\n","# from seglearn.feature_functions import maximum,minimum\n","# from sklearn.preprocessing import normalize,MinMaxScaler\n","\n","batchSize = 2048\n","\n","with open(\"file1.txt\",'r') as file:\n","    y = np.loadtxt(file,delimiter=',')\n","y = np.reshape(y,(-1,batchSize))\n","y = np.reshape(y,(1,-1))\n","segment = SegmentX(width=batchSize, step=batchSize, shuffle=False, random_state=None, order='F')\n","y = segment.transform(y)[0]\n","maxy = maximum(y)\n","miny = minimum(y)\n","\n","loi = y[0:10]\n","loi = np.reshape(loi,(1,-1))\n","loi = loi[0]\n","# loi[loi>1000] = np.mean(y)\n","\n","peaks,upper,lower = find_peaks(loi,height_thres=2,mean_thres=2,width = 20,mode=1)\n","\n","\n","# plt.plot(loi)\n","# plt.plot(upper,loi[upper],\"x\")\n","plt.plot(np.arange(0,len(upper)),loi[upper])\n","plt.plot(np.arange(0,len(lower)),loi[lower])\n","# plt.axis([6200,6300,200,500])\n","# print(loi[5580:5595])\n","# print(upper[8])\n","# print(loi[upper[8]])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPJjhf4Mmzla","colab_type":"code","colab":{}},"source":["import numpy as np\n","a = np.array([1,4,2,5,3])\n","a[[False,False,False,False,True]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yh7b82y-oL8N","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oLiAqxIeMcEt","colab_type":"text"},"source":["## random forest"]},{"cell_type":"code","metadata":{"id":"yyDDX4eZIoQr","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from scipy import signal\n","import heapq\n","\n","def find_peaks(L, mean_thres = 0, height_thres = 0, width = 200, mode = 0):\n","    res = []\n","    upper=[]\n","    lower=[]\n","    register = 0\n","    mean = L[0] - signal.detrend(L)[0]-2\n","    \n","    if(mean_thres == 0):\n","        mean_thres = np.ptp(L)/20\n","    if(height_thres == 0):\n","        height_thres = mean_thres\n","#     plt.figure(figsize=(20,8))\n","#     plt.hlines(mean+mean_thres,0,len(L))    \n","#     plt.hlines(mean,0,len(L))\n","\n","    # status flag\n","    # 0 -- starting\n","    # 1 -- \n","    # 2 -- not determined\n","    # 3 -- not determined\n","    # 4 -- not determined\n","\n","    status = 0 \n","    jump_flag = 0\n","    i = 0\n","#     for i in range(len(L)-1):\n","    while(True):\n","        i+=1\n","        if(i+1 >= len(L)):\n","            break\n","        \n","        if(L[i] > max(mean_thres,height_thres) + mean or L[i] < - max(mean_thres,height_thres) + mean):\n","            if(L[i] > max(mean_thres,height_thres) + mean):\n","                status=1\n","            else:\n","                status=3\n","            if(status==1):\n","                #开始下降\n","                if(L[i]>L[i+1]):\n","                    #未来width个点没有比这个更高的 || 低下了mean下thres\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] >= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif( L[i+j] < - mean_thres + mean):\n","                            res.append(i)\n","                            upper.append(i)\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","\n","            elif(status==3):\n","                if(L[i]<=L[i+1]):\n","                    for j in range(1,len(L)-i):\n","                        if( L[i+j] <= L[i] ):\n","                            i = i+j-1\n","                            jump_flag = 1\n","                            break\n","                        elif(L[i+j]>mean_thres+mean):\n","                            res.append(i)\n","                            lower.append(i)\n","                            i=i+j-1\n","                            jump_flag = 1\n","                            break\n","                    if(jump_flag == 1):\n","                        jump_flag = 0\n","                else:\n","                    status = 0\n","    \n","    \n","    lower = np.array(lower)\n","    upper = np.array(upper)\n","    res = np.array(res)\n","    return (res,upper,lower)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQdDpF0IMfSY","colab_type":"code","colab":{}},"source":["# --------read-----------\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","import sys,os\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.decomposition import PCA\n","from sklearn import svm\n","\n","\n","\n","names = [\"cjc\", \"qst\", \"smj\"]\n","PATH = 'data/output/'\n","\n","X = np.array([[]])\n","y = np.array([])\n","\n","maxlen=0\n","for people in names:\n","    for i in range(1, 11):\n","        for j in range(10):\n","            curr_file = PATH + people + '_' + str(i) + '_' + str(j) + '_filtered.txt'\n","            data = np.array([])\n","            with open(curr_file,'r') as file:\n","                for line in file:\n","                    line = line[:-2]\n","                    data = np.append(data,line.split(\",\"))\n","                y = np.append(y,i-1)\n","            data = data.reshape(-1,1)\n","            data = np.array([float(_) for _ in data])\n","            if len(data)>maxlen:\n","                maxlen = len(data)\n","\n","            value = np.array([])\n","            #fft\n","            value = np.abs(np.fft.rfft(data,n=maxlen))[:]\n","            value = [value[:150]]\n","#             #extra feature 1\n","#             if(i==1):\n","#                 value = np.append(value,50)\n","#             elif(i==2):\n","#                 value = np.append(value,0)\n","#             elif(i==3):\n","#                 value = np.append(value,50)\n","#             elif(i==4):\n","#                 value = np.append(value,0)\n","#             else:\n","#                 value = np.append(value,0)\n","                \n","#             #extra feature 2\n","            peaks,upper,lower = find_peaks(data,height_thres=0.1,mean_thres=0.1,width = 10,mode=1)\n","#             print(1)\n","#             plt.figure()\n","#             plt.plot(data)\n","#             if(len(upper)):plt.plot(upper,data[upper],marker='*')\n","#             if(len(lower)):plt.plot(lower,data[lower],marker='*')\n","#             plt.show()\n","            value = np.append(value,len(peaks))\n","            value = np.append([value],peaks)\n","#             value = np.append(value,len(upper))\n","#             value = np.append(value,len(lower))\n","            \n","#             # the average distance of peaks\n","            \n","            value = np.append(value,max(data))\n","            value = np.append(value,min(data))\n","            value = [value]\n","            \n","            try:\n","                X = np.concatenate((X,value),axis=0)\n","            except:\n","                X = value\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lt25nkJpftgb","colab_type":"code","colab":{}},"source":["# --------starts here-------\n","# --------read-----------\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import sys,os\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.decomposition import PCA\n","from sklearn import svm\n","\n","skip_list = [2,4,10,12,20]\n","\n","y=[]\n","\n","for k in range(9):\n","    for i in range(22):\n","        if i in skip_list:\n","            continue\n","        for j in range(10):\n","            y.append(i)\n","\n","# for i in range(22):\n","#     for j in range(30):\n","#         y.append(i)\n","\n","print(y)\n","\n","tsfresh_feature = pd.read_csv(\"data/features_filtered_user.csv\")\n","\n","tsfresh_feature = tsfresh_feature.drop([\"id\"],axis=1)\n","tsfresh_feature = tsfresh_feature.drop([i for i in range(7*220,(7+1)*220)])\n","\n","for i in range(10):\n","    for skipping in skip_list:\n","        try:\n","            tsfresh_feature = tsfresh_feature.drop([skipping*10+j+i*220 for j in range(10)])\n","        except:\n","            print(i)\n","# for idx in range(10):\n","\n","X = tsfresh_feature[:]\n","y = y\n","print(X.shape)\n","maxyhat_train=0.0\n","maxyhat_test=0.0\n","temp = 0\n","feature_list=[]\n","result_list = np.zeros(100)\n","train_results = []\n","test_results = []\n","for i in range(10,20):\n","    for j in range(10,20):\n","        x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=i, train_size=0.75, test_size=0.25)\n","\n","        clf = RandomForestClassifier(n_estimators=100, max_depth=30, random_state=j)\n","        clf.fit(x_train, y_train)\n","        temp = clf.score(x_train, y_train)\n","        train_results.append(temp)\n","        if (temp > maxyhat_train).any():\n","            maxyhat_train = temp\n","        temp = clf.score(x_test, y_test)\n","        test_results.append(temp)\n","        feature_importances = pd.DataFrame(clf.feature_importances_,\n","                                   index = x_train.columns,\n","                                    columns=['importance']).sort_values('importance',ascending=False)\n","        result_list[(i-10)*10+(j-10)] = temp\n","        if (maxyhat_test < temp).any():\n","            maxyhat_test = temp\n","            for feature in feature_importances.index.tolist()[:50]:\n","                if not feature in feature_list:\n","                    feature_list.append(feature)\n","\n","                    \n","print(maxyhat_train)\n","print(maxyhat_test)\n","\n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(np.arange(100), train_results,'b', label='Train AUC')\n","line2, = plt.plot(np.arange(100), test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('n_estimators')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzxHqMK32RkA","colab_type":"code","colab":{}},"source":["tsfresh_feature"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wejf2N49zJHi","colab_type":"code","colab":{}},"source":["#------ using ranked features ----------#\n","train_results = []\n","test_results = []\n","for i in range(10,20):\n","    for j in range(10,20):\n","        x_train, x_test, y_train, y_test = train_test_split(X[feature_list], y, random_state=i, train_size=0.8, test_size=0.2)\n","        clf = RandomForestClassifier(n_estimators=100, max_depth=30, random_state=j)\n","#         clf = svm.SVC(C=0.4,kernel='linear',gamma=5)\n","        clf.fit(x_train, y_train)\n","        temp = clf.score(x_train, y_train)\n","        train_results.append(temp)\n","        if (temp > maxyhat_train).any():\n","            maxyhat_train = temp\n","        temp = clf.score(x_test, y_test)\n","        test_results.append(temp)\n","        if (maxyhat_test < temp).any():\n","            maxyhat_test = temp\n","\n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(np.arange(100), train_results,'b', label='Train AUC')\n","line2, = plt.plot(np.arange(100), test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('n_estimators')\n","plt.show()\n","print(maxyhat_train)\n","print(maxyhat_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyi45Tew8jOT","colab_type":"code","colab":{}},"source":["#------ adding features from Shutong ------#\n","# fftfeatures1 = np.loadtxt(fname = \"data/22gesture.txt\",delimiter=',')\n","# fftfeatures = np.loadtxt(fname = \"data/qstSpectro.txt\",delimiter=',')\n","# fftfeatures = np.concatenate((fftfeatures1,fftfeatures2),axis=0)\n","fftfeatures = np.loadtxt(fname = \"data/userStudy.txt\",delimiter=',')\n","print(fftfeatures.shape)\n","_len = len(fftfeatures[:][0])\n","fft_df = pd.DataFrame(data=fftfeatures[:],    # values\n","              index=[i for i in range(2200)],    # 1st column as index\n","              columns=[\"f\"+str(i) for i in range(_len)])\n","\n","fft_df = fft_df.drop([i for i in range(7*220,(7+1)*220)])\n","\n","for i in range(10):\n","    for skipping in skip_list:\n","        try:\n","            fft_df = fft_df.drop([skipping*10+j+i*220 for j in range(10)])\n","        except:\n","            print(i)\n","\n","features_combine = fft_df.join(X[feature_list])\n","features_combine.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrLoIw6iFeOb","colab_type":"code","colab":{}},"source":["#------------ Random Forest -------------#\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","import serial\n","import sys,os\n","from seglearn.transform import SegmentX\n","from seglearn.feature_functions import maximum,minimum\n","from sklearn.preprocessing import normalize,MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.decomposition import PCA\n","from sklearn import svm\n","\n","X = features_combine\n","print(X.shape)\n","maxyhat_train=0.0\n","maxyhat_test=0.0\n","temp = 0\n","\n","\n","result_list = np.zeros(100)\n","train_results = []\n","test_results = []\n","for i in range(10,20):\n","    for j in range(10,20):\n","        x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.8, test_size=0.2)\n","\n","        clf = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=j)\n","#         clf = svm.SVC(C=0.4,kernel='linear',gamma=5)\n","        clf.fit(x_train, y_train)\n","        temp = clf.score(x_train, y_train)\n","        train_results.append(temp)\n","\n","        if (temp > maxyhat_train).any():\n","            maxyhat_train = temp\n","        #show_accuracy(y_hat, y_train, '训练集')\n","        temp = clf.score(x_test, y_test)\n","        test_results.append(temp)\n","\n","#         print(temp)\n","\n","        feature_importances = pd.DataFrame(clf.feature_importances_,\n","                                   index = x_train.columns,\n","                                    columns=['importance']).sort_values('importance',ascending=False)\n","        result_list[(i-10)*10+(j-10)] = temp\n","        if (maxyhat_test < temp).any():\n","            maxyhat_test = temp\n","            for feature in feature_importances.index.tolist()[:50]:\n","                if not feature in feature_list:\n","                    feature_list.append(feature)\n","            print(len(feature_list))\n","            \n","        #show_accuracy(y_hat, y_test, '测试集')\n","\n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(np.arange(100), train_results,'b', label='Train AUC')\n","line2, = plt.plot(np.arange(100), test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('n_estimators')\n","plt.show()\n","\n","print(maxyhat_train)\n","print(maxyhat_test)\n","\n","train_results\n","test_results\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOacl4-4GgAa","colab_type":"code","colab":{}},"source":["#------ using ranked features ----------#\n","bestmodel = 0\n","maxyhat_test=0\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","import matplotlib.pyplot as plt\n","\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Only use the labels that appear in the data\n","    classes = classes[unique_labels(y_true, y_pred)]\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","#     print(cm)\n","\n","    fig, ax = plt.subplots(figsize=(15,15))\n","    \n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    ax.figure.colorbar(im, ax=ax)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='True label',\n","           xlabel='Predicted label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","             rotation_mode=\"anchor\")\n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    fig.tight_layout()\n","    return ax\n","\n","v2_names = [\"button_on\", \"button_off\", \"calling\", \"check\", \"circle\", \"double_tap\", \"fast_swipe\", \"finger_press\", \"finger_rub\", \"finger_slide\",\n","        \"hand_rotation\", \"hold\", \"horizontal_swipe\", \"palm_tilt\", \"pull\", \"push\", \"ranctangle\", \"round\", \"single_tap\", \"slow_swipe\",\n","        \"snapping_finger\", \"triangle\"]\n","\n","v2_names = np.array(v2_names)\n","y_pred = None\n","for i in range(10,20):\n","    for j in range(10,20):\n","        x_train, x_test, y_train, y_test = train_test_split(X[feature_list], y, random_state=i, train_size=0.9, test_size=0.1)\n","#         x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=i, train_size=0.8, test_size=0.2)\n","\n","        clf = RandomForestClassifier(n_estimators=100, max_depth=50, random_state=j)\n","#         clf = svm.SVC(C=0.4,kernel='linear',gamma=5)\n","        model = clf.fit(x_train, y_train)\n","        temp_train = clf.score(x_train, y_train)\n","        \n","        temp_test = clf.score(x_test, y_test)\n","        if (maxyhat_test < temp_test).any():\n","            y_pred = clf.predict(x_test)\n","            maxyhat_train = temp_train\n","            maxyhat_test = temp_test\n","            plot_confusion_matrix(y_test, y_pred, classes=v2_names, normalize=True,\n","                      title='Normalized confusion matrix')\n","            plt.show()\n","            print(maxyhat_test)\n","print(maxyhat_train)\n","print(maxyhat_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sw9uddryFl2-","colab_type":"text"},"source":["## parameter search"]},{"cell_type":"code","metadata":{"id":"lQpxFXPVFlst","colab_type":"code","colab":{}},"source":["state_list = [30, 42, 41, 89, 85, 81]\n","state_list.reverse()\n","\n","for state in state_list:\n","    i = int(state / 10)\n","    j = state % 10\n","    print(i,j)\n","result_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sYXQCOKFt44","colab_type":"code","colab":{}},"source":["##------- search for n_estimators ---------\n","n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 300]\n","train_results = []\n","test_results = []\n","for estimater in n_estimators:\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.75, test_size=0.25)\n","    clf = RandomForestClassifier(n_estimators=100, random_state=11)\n","    clf.fit(x_train, y_train)\n","    temp = clf.score(x_train, y_train)\n","    train_results.append(temp)\n","    #         print(temp)\n","    if (temp > maxyhat_train).any():\n","        maxyhat_train = temp\n","    #show_accuracy(y_hat, y_train, '训练集')\n","    temp = clf.score(x_test, y_test)\n","    test_results.append(temp)\n","\n","    #         print(temp)\n","    feature_importances = pd.DataFrame(clf.feature_importances_,\n","                               index = x_train.columns,\n","                                columns=['importance']).sort_values('importance',ascending=False)\n","    result_list[(i-10)*10+(j-10)] = temp\n","    if (maxyhat_test < temp).any():\n","\n","        maxyhat_test = temp\n","        for feature in feature_importances.index.tolist()[:50]:\n","            if not feature in feature_list:\n","                feature_list.append(feature)\n","                \n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(n_estimators, train_results,'b', label='Train AUC')\n","line2, = plt.plot(n_estimators, test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('n_estimators')\n","plt.show()\n","#100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ebhGWSDLCXD","colab_type":"code","colab":{}},"source":["##------- search for max_depth ---------\n","max_depths = np.linspace(1,32,32,endpoint = True)\n","train_results = []\n","test_results = []\n","for max_depth in max_depths:\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.75, test_size=0.25)\n","    clf = RandomForestClassifier(n_estimators = 100, max_depth = max_depth, random_state=11)\n","    clf.fit(x_train, y_train)\n","    temp = clf.score(x_train, y_train)\n","    train_results.append(temp)\n","    #         print(temp)\n","    if (temp > maxyhat_train).any():\n","        maxyhat_train = temp\n","    #show_accuracy(y_hat, y_train, '训练集')\n","    temp = clf.score(x_test, y_test)\n","    test_results.append(temp)\n","\n","    #         print(temp)\n","    feature_importances = pd.DataFrame(clf.feature_importances_,\n","                               index = x_train.columns,\n","                                columns=['importance']).sort_values('importance',ascending=False)\n","    result_list[(i-10)*10+(j-10)] = temp\n","    if (maxyhat_test < temp).any():\n","\n","        maxyhat_test = temp\n","        for feature in feature_importances.index.tolist()[:50]:\n","            if not feature in feature_list:\n","                feature_list.append(feature)\n","                \n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(max_depths, train_results,'b', label='Train AUC')\n","line2, = plt.plot(max_depths, test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('Tree depth')\n","plt.show()\n","#32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fq_KrL1AIc9B","colab_type":"code","colab":{}},"source":["##------- search for min_samples_split ---------\n","min_samples_splits = np.linspace(0.1,0.2,10,endpoint = True)\n","train_results = []\n","test_results = []\n","for min_samples_split in min_samples_splits:\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.75, test_size=0.25)\n","    clf = RandomForestClassifier(n_estimators = 100, min_samples_split=min_samples_split, random_state=11)\n","    clf.fit(x_train, y_train)\n","    temp = clf.score(x_train, y_train)\n","    train_results.append(temp)\n","    #         print(temp)\n","    if (temp > maxyhat_train).any():\n","        maxyhat_train = temp\n","    #show_accuracy(y_hat, y_train, '训练集')\n","    temp = clf.score(x_test, y_test)\n","    test_results.append(temp)\n","\n","    #         print(temp)\n","    feature_importances = pd.DataFrame(clf.feature_importances_,\n","                               index = x_train.columns,\n","                                columns=['importance']).sort_values('importance',ascending=False)\n","    if (maxyhat_test < temp).any():\n","\n","        maxyhat_test = temp\n","        for feature in feature_importances.index.tolist()[:50]:\n","            if not feature in feature_list:\n","                feature_list.append(feature)\n","                \n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(min_samples_splits, train_results,'b', label='Train AUC')\n","line2, = plt.plot(min_samples_splits, test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('min samples split')\n","plt.show()\n","#0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSK1camMxLBi","colab_type":"code","colab":{}},"source":["##------- search for min_samples_leaf ---------\n","min_samples_leafs = np.linspace(0.01,0.1,10,endpoint = True)\n","train_results = []\n","test_results = []\n","for min_samples_leaf in min_samples_leafs:\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.75, test_size=0.25)\n","    clf = RandomForestClassifier(n_estimators = 100, max_depth = max_depth,min_samples_leaf=min_samples_leaf, random_state=11)\n","    clf.fit(x_train, y_train)\n","    temp = clf.score(x_train, y_train)\n","    train_results.append(temp)\n","    #         print(temp)\n","    if (temp > maxyhat_train).any():\n","        maxyhat_train = temp\n","    #show_accuracy(y_hat, y_train, '训练集')\n","    temp = clf.score(x_test, y_test)\n","    test_results.append(temp)\n","\n","    #         print(temp)\n","    feature_importances = pd.DataFrame(clf.feature_importances_,\n","                               index = x_train.columns,\n","                                columns=['importance']).sort_values('importance',ascending=False)\n","    result_list[(i-10)*10+(j-10)] = temp\n","    if (maxyhat_test < temp).any():\n","\n","        maxyhat_test = temp\n","        for feature in feature_importances.index.tolist()[:50]:\n","            if not feature in feature_list:\n","                feature_list.append(feature)\n","                \n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(min_samples_leafs, train_results,'b', label='Train AUC')\n","line2, = plt.plot(min_samples_leafs, test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('min samples split')\n","plt.show()\n","#0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKfygmHZxW1W","colab_type":"code","colab":{}},"source":["##------- search for min_samples_leaf ---------\n","max_features = list(range(1,X.shape[1]))\n","min_samples_leafs = np.linspace(0.1,0.5,5,endpoint = True)\n","train_results = []\n","test_results = []\n","for max_feature in max_features:\n","    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=18, train_size=0.75, test_size=0.25)\n","    clf = RandomForestClassifier(n_estimators = 100, max_depth = max_depth,max_features=max_feature, random_state=11)\n","    clf.fit(x_train, y_train)\n","    temp = clf.score(x_train, y_train)\n","    train_results.append(temp)\n","    #         print(temp)\n","    if (temp > maxyhat_train).any():\n","        maxyhat_train = temp\n","    #show_accuracy(y_hat, y_train, '训练集')\n","    temp = clf.score(x_test, y_test)\n","    test_results.append(temp)\n","\n","    #         print(temp)\n","    feature_importances = pd.DataFrame(clf.feature_importances_,\n","                               index = x_train.columns,\n","                                columns=['importance']).sort_values('importance',ascending=False)\n","    result_list[(i-10)*10+(j-10)] = temp\n","    if (maxyhat_test < temp).any():\n","\n","        maxyhat_test = temp\n","        for feature in feature_importances.index.tolist()[:50]:\n","            if not feature in feature_list:\n","                feature_list.append(feature)\n","                \n","from matplotlib.legend_handler import HandlerLine2D\n","line1, = plt.plot(max_features, train_results,'b', label='Train AUC')\n","line2, = plt.plot(max_features, test_results,'r', label='Test AUC')\n","plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n","plt.ylabel('AUC score')\n","plt.xlabel('min samples split')\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IvXZnOuq0qqC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RH92nDz71a5B","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}